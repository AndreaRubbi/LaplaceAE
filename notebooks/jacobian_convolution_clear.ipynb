{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d19c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../stochman/\")\n",
    "\n",
    "from stochman import nnj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f4c39",
   "metadata": {},
   "source": [
    "# Define convolution parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2cf76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "conv: \t\t\t weights torch.Size([5, 3, 7, 8]) \t- input torch.Size([2, 3, 20, 23]) \t- output torch.Size([2, 5, 16, 24])\n",
      "conv_dw: \t\t weights torch.Size([3, 2, 20, 23]) \t- input torch.Size([5, 3, 7, 8]) \t- output torch.Size([2, 5, 16, 24])\n",
      "conv_transposed: \t weights torch.Size([5, 3, 7, 8]) \t- input torch.Size([2, 5, 16, 24]) \t- output torch.Size([2, 3, 20, 23])\n",
      "conv_dw_transposed: \t weights torch.Size([3, 2, 20, 23]) \t- input torch.Size([5, 2, 16, 24]) \t- output torch.Size([5, 3, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "def compute_output_edge(input_edge, kernel_size=1,padding=0,stride=1,dilation=1):\n",
    "    output_edge = ( input_edge - dilation*(kernel_size-1) + 2*padding -1 )/stride +1 #output edge can be not-integer if stride!=1\n",
    "    return int(output_edge)\n",
    "def compute_output_padding(input_edge, output_edge, kernel_size=1,padding=0,stride=1,dilation=1):\n",
    "    return input_edge - ((output_edge-1)*stride - 2*padding + dilation*(kernel_size-1) + 1)\n",
    "def compute_reversed_padding(padding, kernel_size=1):\n",
    "    return kernel_size - 1 - padding\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "# Set parameters (free to change)\n",
    "batch_size = 2\n",
    "IN_c, OUT_c = 3, 5 #number of channels (for input and output)\n",
    "IN_h, IN_w = 20, 23 #number of pixels per input edges\n",
    "kernel_h, kernel_w = 7, 8\n",
    "set_padding_for_shape_preserving = False #not needed\n",
    "if set_padding_for_shape_preserving:\n",
    "    assert kernel_h%2==1 and kernel_w%2==1\n",
    "    padding_h, padding_w = int((kernel_h-1)/2), int((kernel_w-1)/2)\n",
    "else:\n",
    "    padding_h, padding_w = 1, 4\n",
    "stride = 1 #don't change me please, bad things will happen\n",
    "dilation = 1\n",
    "\n",
    "##############################################################################\n",
    "# Compute output sizes\n",
    "OUT_h, OUT_w = compute_output_edge(IN_h, kernel_size=kernel_h, padding=padding_h, stride=stride, dilation=dilation), compute_output_edge(IN_w, kernel_size=kernel_w, padding=padding_w, stride=stride, dilation=dilation)\n",
    "# Compute output padding for conv transpose\n",
    "out_padding_h, out_padding_w = compute_output_padding(IN_h, OUT_h, kernel_size=kernel_h, padding=padding_h, stride=stride, dilation=dilation), compute_output_padding(IN_w, OUT_w, kernel_size=kernel_w, padding=padding_w, stride=stride, dilation=dilation)\n",
    "dw_padding_h, dw_padding_w = compute_reversed_padding(padding_h, kernel_size=kernel_h), compute_reversed_padding(padding_w, kernel_size=kernel_w)\n",
    "dw_reversed_padding_h, dw_reversed_padding_w = compute_reversed_padding(padding_h, kernel_size=IN_h), compute_reversed_padding(padding_w, kernel_size=IN_w)\n",
    "print(out_padding_h, out_padding_w)\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "# Define convolutional layer\n",
    "conv = nnj.Conv2d(IN_c, \n",
    "                  OUT_c, \n",
    "                  kernel_size=(kernel_h, kernel_w), \n",
    "                  padding=(padding_h,padding_w), \n",
    "                  stride=stride, dilation=dilation, bias=None)\n",
    "assert list(conv.weight.shape) == [OUT_c, IN_c, kernel_h, kernel_w]\n",
    "# Define input images. Compute output images\n",
    "inputs = torch.randint(0, 10, (batch_size, IN_c, IN_h, IN_w)).type(torch.float)\n",
    "outputs = conv(inputs)\n",
    "assert list(outputs.shape) == [batch_size, OUT_c, OUT_h, OUT_w]\n",
    "print('conv: \\t\\t\\t weights',conv.weight.shape, '\\t- input',inputs.shape, '\\t- output',outputs.shape)\n",
    "\n",
    "# Define reversed convolutional layer (same operator as conv but with switched input/weights)\n",
    "conv_dw = nnj.ConvTranspose2d(IN_c, \n",
    "                              batch_size, \n",
    "                              kernel_size=(IN_h,IN_w), \n",
    "                              padding=(dw_padding_h,dw_padding_w), \n",
    "                              stride=stride, dilation=dilation, output_padding=0, bias=None)\n",
    "reversed_inputs = torch.flip(inputs, [-2,-1]).movedim(0,1)\n",
    "assert conv_dw.weight.shape == reversed_inputs.shape\n",
    "conv_dw.weight = torch.nn.Parameter(reversed_inputs)\n",
    "dw_outputs = torch.flip(conv_dw(conv.weight), [-2,-1]).movedim(0,1)\n",
    "assert torch.max(dw_outputs - outputs) < 1e-5 #chek that the two operators are actually the same\n",
    "print('conv_dw: \\t\\t weights',conv_dw.weight.shape, '\\t- input',conv.weight.shape, '\\t- output',dw_outputs.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define transposed of convolutional layer\n",
    "conv_transposed = nnj.ConvTranspose2d(OUT_c, \n",
    "                                      IN_c, \n",
    "                                      kernel_size=(kernel_h,kernel_w), \n",
    "                                      padding=(padding_h,padding_w), \n",
    "                                      stride=stride, dilation=dilation, bias=None, \n",
    "                                      output_padding=(out_padding_h,out_padding_w))\n",
    "conv_transposed.weight = conv.weight\n",
    "assert conv_transposed(outputs).shape == inputs.shape\n",
    "print('conv_transposed: \\t weights',conv_transposed.weight.shape, '\\t- input',outputs.shape, '\\t- output',conv_transposed(outputs).shape)\n",
    "\n",
    "# Define reversed transposed convolutional layer\n",
    "conv_dw_transposed = nnj.Conv2d(batch_size, \n",
    "                                IN_c, \n",
    "                                kernel_size=(IN_h,IN_w), \n",
    "                                padding=(dw_padding_h,dw_padding_w), \n",
    "                                stride=stride, dilation=dilation, bias=None) # output_padding=0\n",
    "reversed_inputs = torch.flip(inputs, [-2,-1]).movedim(0,1)\n",
    "assert conv_dw.weight.shape == reversed_inputs.shape\n",
    "conv_dw_transposed.weight = torch.nn.Parameter(reversed_inputs)\n",
    "dw_weights = torch.flip(conv_dw_transposed(outputs.movedim(0,1)), [-2,-1])\n",
    "print('conv_dw_transposed: \\t weights',conv_dw_transposed.weight.shape, '\\t- input',outputs.movedim(0,1).shape, '\\t- output',dw_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d7e9d",
   "metadata": {},
   "source": [
    "# Jacobian of convolution [wrt. input]\n",
    "Computation of the full Jacobian (we don't want to do that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df86123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1920, 1380]) torch.Size([2, 1380, 1920])\n"
     ]
    }
   ],
   "source": [
    "IN_size, OUT_size = IN_c*IN_h*IN_w, OUT_c*OUT_h*OUT_w\n",
    "\n",
    "def conv_jacobian_wrt_input():\n",
    "    # define base elements on input, one for each batch size\n",
    "    output_identity = torch.eye(IN_size).unsqueeze(0).expand(batch_size,-1,-1)\n",
    "    assert list(output_identity.shape) == [batch_size, IN_size, IN_size]\n",
    "    # expand rows as cubes [(input channel)x(input height)x(input width)]\n",
    "    output_identity = output_identity.reshape(batch_size, IN_c, IN_h, IN_w, IN_size)\n",
    "    # define the shapes required by torch.conv2d\n",
    "    #  - from cube [(input channel)x(input height)x(input width)]\n",
    "    #  - to cube   [(output channel)x(output height)x(output width)]\n",
    "    input_for_shape = torch.zeros(batch_size,IN_c,IN_h,IN_w)\n",
    "    output_for_shape = torch.zeros(batch_size,OUT_c,OUT_h,OUT_w)\n",
    "    # convolve each base element and compute the jacobian\n",
    "    jacobian = conv._jacobian_mult(input_for_shape, output_for_shape, output_identity)\n",
    "    # reshape as a (num of output)x(num of input) matrix, one for each batch size\n",
    "    jacobian = jacobian.reshape(batch_size, OUT_size, IN_size)\n",
    "    return jacobian\n",
    "\n",
    "def conv_jacobian_wrt_input_T():\n",
    "    # define base elements on output, one for each batch size\n",
    "    output_identity = torch.eye(OUT_size).unsqueeze(0).expand(batch_size,-1,-1)\n",
    "    assert list(output_identity.shape) == [batch_size, OUT_size, OUT_size]\n",
    "    # expand rows as cubes [(output channel)x(output height)x(output width)]\n",
    "    output_identity = output_identity.reshape(batch_size, OUT_c, OUT_h, OUT_w, OUT_size)\n",
    "    # define the shapes required by torch.conv2d (transposed)\n",
    "    #  - from cube [(output channel)x(output height)x(output width)]\n",
    "    #  - to cube   [(input channel)x(input height)x(input width)]\n",
    "    input_for_shape = torch.zeros(batch_size,OUT_c,OUT_h,OUT_w)\n",
    "    output_for_shape = torch.zeros(batch_size,IN_c,IN_h,IN_w)\n",
    "    # convolve each base element and compute the jacobian\n",
    "    jacobian = conv_transposed._jacobian_mult(input_for_shape, output_for_shape, output_identity)\n",
    "    # reshape as a (num of input)x(num of output) matrix, one for each batch size\n",
    "    jacobian = jacobian.reshape(batch_size, IN_size, OUT_size)\n",
    "    return jacobian\n",
    "\n",
    "# the two functions should return the same matrix, but transposed\n",
    "\n",
    "# check if the shape are one the transposed of the other\n",
    "print(conv_jacobian_wrt_input().shape, conv_jacobian_wrt_input_T().shape)\n",
    "assert conv_jacobian_wrt_input().shape == conv_jacobian_wrt_input_T().movedim(-1,-2).shape\n",
    "# check if the elements are the same\n",
    "assert torch.max( conv_jacobian_wrt_input() - conv_jacobian_wrt_input_T().movedim(-1,-2) ) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234d92b",
   "metadata": {},
   "source": [
    "# Jacobian of convolution [wrt. weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f5c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1920, 840]) torch.Size([2, 840, 1920])\n"
     ]
    }
   ],
   "source": [
    "def conv_jacobian_wrt_weight():\n",
    "    # define base elements on weights\n",
    "    output_identity = torch.eye(OUT_c*IN_c*kernel_h*kernel_w)\n",
    "    # expand rows as [(input channels)x(kernel height)x(kernel width)] cubes, one for each output channel\n",
    "    output_identity = output_identity.reshape(OUT_c, IN_c,kernel_h,kernel_w, OUT_c*IN_c*kernel_h*kernel_w)\n",
    "    # define the shapes required by torch.conv2d (transposed)\n",
    "    #  - from cube [(input channels)x(kernel height)x(kernel width)]\n",
    "    #  - to cube   [(batch size)x(output height)x(output width)]\n",
    "    # one for each output channel\n",
    "    input_for_shape = torch.zeros(OUT_c,IN_c,kernel_h,kernel_w)\n",
    "    output_for_shape = torch.zeros(OUT_c,batch_size,OUT_h,OUT_w)\n",
    "    # convolve each base element and compute the jacobian\n",
    "    jacobian = conv_dw._jacobian_mult(input_for_shape, output_for_shape, output_identity)\n",
    "    # transpose the result in (output height)x(output width)\n",
    "    jacobian = torch.flip(jacobian, [-3, -2])\n",
    "    # switch batch size and output channel\n",
    "    jacobian = jacobian.movedim(0,1)\n",
    "    # reshape as a (num of output)x(num of weights) matrix, one for each batch size\n",
    "    jacobian = jacobian.reshape(batch_size, OUT_size, OUT_c*IN_c*kernel_h*kernel_w)\n",
    "    return jacobian\n",
    "\n",
    "matrix_operator_from_input_to_output = conv_jacobian_wrt_input()\n",
    "output_computed_classically = torch.einsum('Bij,Bj->Bi',matrix_operator_from_input_to_output , inputs.reshape(batch_size,IN_size) ).reshape(batch_size,OUT_c,OUT_h,OUT_w)\n",
    "matrix_operator_from_weight_to_output = conv_jacobian_wrt_weight()\n",
    "output_computed_reversed = torch.einsum('Bij,j->Bi', matrix_operator_from_weight_to_output, conv.weight.reshape(-1)).reshape(batch_size,OUT_c,OUT_h,OUT_w)\n",
    "# check that conv and conv_dw actually represent the same operator\n",
    "assert torch.max(output_computed_classically - output_computed_reversed) < 1e-5\n",
    "\n",
    "def conv_jacobian_wrt_weight_T():\n",
    "    # define base elements on output, one for each batch size\n",
    "    output_identity = torch.eye(batch_size*OUT_size)\n",
    "    # expand rows as cubes [(output channel)x(output height)x(output width)]\n",
    "    output_identity = output_identity.reshape(batch_size, OUT_c, OUT_h, OUT_w, batch_size*OUT_size)\n",
    "    # transpose the images in (output height)x(output width)\n",
    "    output_identity = torch.flip(output_identity, [-3, -2])\n",
    "    # switch batch size and output channel\n",
    "    output_identity = output_identity.movedim(0,1)\n",
    "    # define the shapes required by torch.conv2d (transposed)\n",
    "    #  - from cube [(batch size)x(output height)x(output width)]\n",
    "    #  - to cube   [(input channels)x(kernel height)x(kernel width)]\n",
    "    input_for_shape = torch.zeros(OUT_c,batch_size,OUT_h,OUT_w)\n",
    "    output_for_shape = torch.zeros(OUT_c,IN_c,kernel_h,kernel_w)\n",
    "    # convolve each base element and compute the jacobian\n",
    "    jacobian = conv_dw_transposed._jacobian_mult(input_for_shape, output_for_shape, output_identity)\n",
    "    # reshape as a (num of weights)x(num of output) matrix\n",
    "    jacobian = jacobian.reshape(OUT_c*IN_c*kernel_h*kernel_w, batch_size, OUT_size)\n",
    "    # switch batch size and kernel size\n",
    "    jacobian = jacobian.movedim(0,1)\n",
    "    return jacobian\n",
    "\n",
    "# the two functions should return the same matrix, but transposed\n",
    "\n",
    "# check if the shape are one the transposed of the other\n",
    "print(conv_jacobian_wrt_weight().shape, conv_jacobian_wrt_weight_T().shape)\n",
    "assert conv_jacobian_wrt_weight().shape == conv_jacobian_wrt_weight_T().movedim(-1,-2).shape\n",
    "# check if the elements are the same\n",
    "assert torch.max( conv_jacobian_wrt_weight() - conv_jacobian_wrt_weight_T().movedim(-1,-2) ) < 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45bcba9",
   "metadata": {},
   "source": [
    "# Assert jacobian wrt weights is correct\n",
    "Comparing to row-by-row computation (single layer NN, for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb5e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asdfghjkl.gradient import batch_gradient\n",
    "\n",
    "def _flatten_after_batch(tensor: torch.Tensor):\n",
    "    if tensor.ndim == 1:\n",
    "        return tensor.unsqueeze(-1)\n",
    "    else:\n",
    "        return tensor.flatten(start_dim=1)\n",
    "        \n",
    "def _get_batch_grad(model):\n",
    "    batch_grads = list()\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'op_results'):\n",
    "            res = module.op_results['batch_grads']\n",
    "            if 'weight' in res:\n",
    "                batch_grads.append(_flatten_after_batch(res['weight']))\n",
    "            if 'bias' in res:\n",
    "                batch_grads.append(_flatten_after_batch(res['bias']))\n",
    "            if len(set(res.keys()) - {'weight', 'bias'}) > 0:\n",
    "                raise ValueError(f'Invalid parameter keys {res.keys()}')\n",
    "    return torch.cat(batch_grads, dim=1)\n",
    "    \n",
    "def jacobians(x, model, output_channel, output_h, output_w):\n",
    "    \"\"\"Compute Jacobians \\\\(\\\\nabla_\\\\theta f(x;\\\\theta)\\\\) at current parameter \\\\(\\\\theta\\\\)\n",
    "    using asdfghjkl's gradient per output dimension.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        input data `(batch, input_shape)` on compatible device with model.\n",
    "    Returns\n",
    "    -------\n",
    "    Js : torch.Tensor\n",
    "        Jacobians `(batch, parameters, outputs)`\n",
    "    f : torch.Tensor\n",
    "        output function `(batch, outputs)`\n",
    "    \"\"\"\n",
    "    Js = list()\n",
    "    for c in range(output_channel):\n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                def loss_fn(outputs, targets):\n",
    "                    return outputs[:, c, i, j].sum()\n",
    "\n",
    "                f = batch_gradient(model, loss_fn, x, None).detach()\n",
    "                Jk = _get_batch_grad(model)\n",
    "\n",
    "                Js.append(Jk)\n",
    "    Js = torch.stack(Js, dim=1)\n",
    "    return Js, f\n",
    "\n",
    "# the two functions should return the same matrix\n",
    "jacobian_wrt_weight_slow, _ = jacobians(inputs, conv, OUT_c, OUT_h, OUT_w)\n",
    "jacobian_wrt_weight_fast = conv_jacobian_wrt_weight()\n",
    "\n",
    "# check if the shape are the same\n",
    "assert jacobian_wrt_weight_slow.shape == jacobian_wrt_weight_fast.shape\n",
    "# check if the elements are the same\n",
    "assert torch.max( jacobian_wrt_weight_slow - jacobian_wrt_weight_fast) < 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88b459",
   "metadata": {},
   "source": [
    "# Right and Left multiplications (J wrt to input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f37140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1380, 1380]) torch.Size([2, 1380, 1380]) torch.Size([2, 1380, 1380])\n"
     ]
    }
   ],
   "source": [
    "def conv_jacobian_wrt_input_T_right_multiply_to(tmp):\n",
    "    \"\"\"\n",
    "    Compute Jacobian^T * tmp\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tmp : torch.Tensor\n",
    "        input data `(batch_size, OUT_size, num_of_cols)`\n",
    "    Returns\n",
    "    -------\n",
    "    product : torch.Tensor\n",
    "        Jacobians `(batch_size, IN_size, num_of_cols)`\n",
    "    \"\"\"\n",
    "    num_of_cols = tmp.shape[-1]\n",
    "    assert list(tmp.shape) == [batch_size, OUT_size, num_of_cols]\n",
    "    # expand rows as cubes [(output channel)x(output height)x(output width)]\n",
    "    tmp = tmp.reshape(batch_size, OUT_c, OUT_h, OUT_w, num_of_cols)\n",
    "    # define the shapes required by torch.conv2d (transposed)\n",
    "    #  - from cube [(output channel)x(output height)x(output width)]\n",
    "    #  - to cube   [(input channel)x(input height)x(input width)]\n",
    "    input_for_shape = torch.zeros(batch_size,OUT_c,OUT_h,OUT_w)\n",
    "    output_for_shape = torch.zeros(batch_size,IN_c,IN_h,IN_w)\n",
    "    # convolve each base element and compute the jacobian\n",
    "    Jt_tmp = conv_transposed._jacobian_mult(input_for_shape, output_for_shape, tmp)\n",
    "    # reshape as a (num of input)x(num of output) matrix, one for each batch size\n",
    "    Jt_tmp = Jt_tmp.reshape(batch_size, IN_size, num_of_cols)\n",
    "    return Jt_tmp\n",
    "\n",
    "def conv_jacobian_wrt_input_left_multiply_to(tmp):\n",
    "    \"\"\"\n",
    "    Compute tmp * Jacobian\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tmp : torch.Tensor\n",
    "        input data `(batch_size, num_of_rows, OUT_size)`\n",
    "    Returns\n",
    "    -------\n",
    "    product : torch.Tensor\n",
    "        Jacobians `(batch_size, num_of_rows, IN_size)`\n",
    "    \"\"\"\n",
    "    num_of_rows = tmp.shape[-2]\n",
    "    assert list(tmp.shape) == [batch_size, num_of_rows, OUT_size]\n",
    "    # expand rows as cubes [(output channel)x(output height)x(output width)]\n",
    "    tmp_rows = tmp.movedim(-1,-2).reshape(batch_size, OUT_c, OUT_h, OUT_w, num_of_rows)\n",
    "    # see rows as columns of the transposed matrix\n",
    "    tmpt_cols = tmp_rows\n",
    "    # define the shapes required by torch.conv2d (transposed)\n",
    "    #  - from cube [(output channel)x(output height)x(output width)]\n",
    "    #  - to cube   [(input channel)x(input height)x(input width)]\n",
    "    input_for_shape = torch.zeros(batch_size,OUT_c,OUT_h,OUT_w)\n",
    "    output_for_shape = torch.zeros(batch_size,IN_c,IN_h,IN_w)\n",
    "    # convolve each base element and compute the jacobian\n",
    "    Jt_tmptt_cols = conv_transposed._jacobian_mult(input_for_shape, output_for_shape, tmpt_cols)\n",
    "    # reshape as a (num of input)x(num of output) matrix, one for each batch size\n",
    "    Jt_tmptt_cols = Jt_tmptt_cols.reshape(batch_size,IN_size,num_of_rows)\n",
    "    # transpose\n",
    "    tmp_J = Jt_tmptt_cols.movedim(1,2)\n",
    "    return tmp_J\n",
    "\n",
    "\n",
    "# define a random tmp matrix\n",
    "tmp = torch.randint(0, 10, (batch_size, OUT_size, OUT_size)).type(torch.float)\n",
    "\n",
    "# compute Jt*tmp*J defining the full jacobians (correct for sure but NOT memory efficient)\n",
    "slow_Jt_tmp_J = torch.einsum('Bji,Bjk,Bkq->Biq',conv_jacobian_wrt_input(),tmp,conv_jacobian_wrt_input())\n",
    "# compute (Jt*tmp)*J efficiently\n",
    "fast_Jt_tmp_J_1 = conv_jacobian_wrt_input_left_multiply_to(conv_jacobian_wrt_input_T_right_multiply_to(tmp))\n",
    "# compute Jt*(tmp*J) efficiently\n",
    "fast_Jt_tmp_J_2 = conv_jacobian_wrt_input_T_right_multiply_to(conv_jacobian_wrt_input_left_multiply_to(tmp))\n",
    "\n",
    "\n",
    "# check if the shape are the same\n",
    "print(slow_Jt_tmp_J.shape, fast_Jt_tmp_J_1.shape, fast_Jt_tmp_J_2.shape)\n",
    "# check if the elements are the same\n",
    "assert torch.max(slow_Jt_tmp_J - fast_Jt_tmp_J_1) < 1e-5\n",
    "assert torch.max(slow_Jt_tmp_J - fast_Jt_tmp_J_2) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9414abb9",
   "metadata": {},
   "source": [
    "# Right and Left multiplications (J wrt to weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c1172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
